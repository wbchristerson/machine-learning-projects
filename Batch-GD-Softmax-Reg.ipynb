{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gothic-clothing",
   "metadata": {},
   "source": [
    "### An Implementation Of Batch Gradient Descent With Early Stopping For Softmax Regression Without Using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eight-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "expensive-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test_split(X, y, test_ratio = 0.2, validation_ratio = 0.2):\n",
    "    total_size = len(X)\n",
    "    test_size = int(total_size * test_ratio)\n",
    "    valid_size = int(total_size * validation_ratio)\n",
    "    train_size = total_size - test_size - valid_size\n",
    "    \n",
    "    permutation_indices = np.random.permutation(total_size)\n",
    "    \n",
    "    X_train = X[permutation_indices[:train_size]]\n",
    "    y_train = y[permutation_indices[:train_size]]\n",
    "    X_valid = X[permutation_indices[train_size:-test_size]]\n",
    "    y_valid = y[permutation_indices[train_size:-test_size]]\n",
    "    X_test = X[permutation_indices[-test_size:]]\n",
    "    y_test = X[permutation_indices[-test_size:]]\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "color-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_scalar(x_i, theta_matrix, output_class_k, true_outcome):\n",
    "    '''return p_k^(i) hat - y_k^(i)'''\n",
    "    \n",
    "    matrix_product = x_i @ theta_matrix\n",
    "    pki_hat = np.exp(matrix_product[output_class_k]) / np.sum(np.exp(matrix_product)) # probability\n",
    "    \n",
    "    yki = 1 if output_class_k == true_outcome else 0\n",
    "    return pki_hat - yki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "professional-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta_gradient(output_class_k, X, y, theta_matrix):\n",
    "    theta_gradient = np.zeros((1, X.shape[1]))\n",
    "    m = X.shape[0]\n",
    "    for x_i, true_outcome in zip(X, y):\n",
    "        theta_gradient += get_gradient_scalar(x_i, theta_matrix, output_class_k, true_outcome) * x_i\n",
    "    \n",
    "    return theta_gradient / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indie-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, t1 = 1, 1\n",
    "\n",
    "def get_step_multiplier(alpha, epoch):\n",
    "    return alpha * (t0 / (t1 + epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "mathematical-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def my_batch_GD(X_train, y_train, X_valid, y_valid, num_output_classes, alpha = 1, epochs = 10):\n",
    "    theta_matrix = np.random.rand(X_train[0].size, num_output_classes)\n",
    "    best_theta_matrix = theta_matrix\n",
    "    best_accuracy_score = accuracy_score(y_valid, np.argmax(X_valid @ theta_matrix, axis=1))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        delta_theta_matrix = np.array([]).reshape((0, X_train.shape[1]))\n",
    "#         print(f\"delta_theta_matrix: {delta_theta_matrix}\")\n",
    "        for k in range(num_output_classes):\n",
    "            delta_theta_matrix = np.vstack(\n",
    "                (delta_theta_matrix, np.array(get_theta_gradient(k, X_train, y_train, theta_matrix)))\n",
    "            )\n",
    "#         print(f\"delta_theta_matrix: \\n{delta_theta_matrix}, \\ntheta_matrix: \\n{theta_matrix}\")\n",
    "        \n",
    "        step_multiplier = get_step_multiplier(alpha, e)\n",
    "        theta_matrix -= step_multiplier * np.transpose(delta_theta_matrix)\n",
    "        \n",
    "        temp_accuracy = accuracy_score(y_valid, np.argmax(X_valid @ theta_matrix, axis=1))\n",
    "        if temp_accuracy > best_accuracy_score:\n",
    "            best_accuracy_score = temp_accuracy\n",
    "            best_theta_matrix = np.copy(theta_matrix)\n",
    "    \n",
    "    print(\"theta_matrix:\")\n",
    "    print(theta_matrix)\n",
    "    print(\"\\nbest_theta_matrix:\")\n",
    "    print(best_theta_matrix)\n",
    "    return best_theta_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "grand-bosnia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_matrix:\n",
      "[[ 0.85429727  1.65845611 -0.18244137]\n",
      " [ 0.81107944  0.97450803  0.01241281]\n",
      " [ 0.98072255  1.40100181 -0.21864462]]\n",
      "\n",
      "best_theta_matrix:\n",
      "[[-1.0723057   3.58501949 -0.18240178]\n",
      " [-1.48357023  3.26907852  0.01249199]\n",
      " [-1.68197382  4.06357941 -0.21852585]]\n",
      "[[-1.0723057   3.58501949 -0.18240178]\n",
      " [-1.48357023  3.26907852  0.01249199]\n",
      " [-1.68197382  4.06357941 -0.21852585]]\n"
     ]
    }
   ],
   "source": [
    "print(my_batch_GD(np.array( [ [1,2,3], [4,5,6], [7,8,9], [10,11,12] ] ), np.array([0, 1, 1, 0]),\n",
    "                  np.array( [ [13,14,15] ] ), np.array([1]), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "hollywood-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_make_prediction(X_train, y_train, X_valid, y_valid, num_output_classes, alpha=1.0, epochs = 10):\n",
    "    theta_matrix = my_batch_GD(X_train, y_train, X_valid, y_valid, num_output_classes, alpha, epochs)\n",
    "    \n",
    "#     print(\"theta_matrix:\")\n",
    "#     print(theta_matrix)\n",
    "    \n",
    "    valid_relative_weights = X_valid @ theta_matrix\n",
    "    train_relative_weights = X_train @ theta_matrix\n",
    "    return np.argmax(valid_relative_weights, axis=1), np.argmax(train_relative_weights, axis=1), theta_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "different-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "equipped-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, (2,3)]\n",
    "y = iris[\"target\"]\n",
    "\n",
    "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = my_test_split(X_with_bias, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "needed-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "150\n",
      "Logistic Regression: 144 / 150: 0.96\n",
      "Accuracy Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Reference regressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=11)\n",
    "softmax_reg.fit(X_with_bias, y)\n",
    "\n",
    "y_pred = softmax_reg.predict(X_with_bias)\n",
    "matches = len(y_pred[y_pred == y])\n",
    "total = len(y_pred)\n",
    "print(len(y_pred[y_pred == y]))\n",
    "print(len(y_pred))\n",
    "print(f\"Logistic Regression: {matches} / {total}: {matches / total}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "virgin-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_matrix:\n",
      "[[ 1.48356796  0.41831849  0.1698247 ]\n",
      " [ 0.07265836  0.47269283  0.33817076]\n",
      " [-0.2215154   0.36102665  1.01339246]]\n",
      "\n",
      "best_theta_matrix:\n",
      "[[ 1.28931799  0.44259767  0.3397955 ]\n",
      " [ 0.1203259   0.45017675  0.31301931]\n",
      " [-0.13388611  0.39265436  0.89413547]]\n",
      "\n",
      "my validation count: 24 / 30\n",
      "validation accuracy score: 0.8\n",
      "my training count: 72 / 90\n",
      "training accuracy score: 0.8\n",
      "\n",
      "my validation predictions  : [0 2 2 1 0 2 1 0 2 0 2 1 2 1 0 0 1 0 1 2 1 0 2 1 2 0 2 2 2 0]\n",
      "true validation predictions: [0 1 2 1 0 2 1 0 2 0 2 2 2 2 0 0 1 0 1 2 1 0 1 1 1 0 2 1 2 0]\n",
      "\n",
      "my training predictions  : [2 2 2 0 2 2 0 2 1 0 0 2 2 2 2 1 1 0 2 2 0 2 2 0 1 0 1 0 0 1 0 1 1 2 2 0 0\n",
      " 2 0 1 0 1 2 2 2 2 0 2 2 1 1 1 2 2 1 0 2 2 1 1 0 1 0 2 2 2 1 2 0 1 2 1 2 0\n",
      " 2 2 2 1 0 1 2 2 1 2 2 0 1 0 2 0]\n",
      "true training predictions: [2 1 1 0 1 2 0 1 1 0 0 2 1 2 2 1 1 0 2 2 0 2 2 0 1 0 1 0 0 1 0 1 1 2 2 0 0\n",
      " 1 0 1 0 1 2 2 2 1 0 1 2 1 1 2 2 1 1 0 2 2 1 1 0 1 0 2 2 1 2 1 0 2 1 1 2 0\n",
      " 2 2 2 1 0 1 2 1 1 2 2 0 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "valid_pred, train_pred, my_theta_matrix = fit_and_make_prediction(X_train, y_train, X_valid, y_valid, 3, epochs = 50)\n",
    "\n",
    "valid_pred_count = len(valid_pred[valid_pred == y_valid])\n",
    "train_pred_count = len(train_pred[train_pred == y_train])\n",
    "\n",
    "print(f\"\\nmy validation count: {valid_pred_count} / {len(valid_pred)}\")\n",
    "print(f\"validation accuracy score: {accuracy_score(y_valid, valid_pred)}\")\n",
    "\n",
    "print(f\"my training count: {train_pred_count} / {len(train_pred)}\")\n",
    "print(f\"training accuracy score: {accuracy_score(y_train, train_pred)}\")\n",
    "\n",
    "print(f\"\\nmy validation predictions  : {valid_pred}\")\n",
    "print(f\"true validation predictions: {y_valid}\")\n",
    "\n",
    "print()\n",
    "print(f\"my training predictions  : {train_pred}\")\n",
    "print(f\"true training predictions: {y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-leonard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
